{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d6d1db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 114\u001b[0m\n\u001b[1;32m    112\u001b[0m my_scheduler \u001b[38;5;241m=\u001b[39m sched\u001b[38;5;241m.\u001b[39mscheduler(time\u001b[38;5;241m.\u001b[39mtime, time\u001b[38;5;241m.\u001b[39msleep)\n\u001b[1;32m    113\u001b[0m my_scheduler\u001b[38;5;241m.\u001b[39menter(tick_seconds, \u001b[38;5;241m1\u001b[39m, update_stocks_collect_stat, (my_scheduler,))\n\u001b[0;32m--> 114\u001b[0m \u001b[43mmy_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/sched.py:149\u001b[0m, in \u001b[0;36mscheduler.run\u001b[0;34m(self, blocking)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blocking:\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m time \u001b[38;5;241m-\u001b[39m now\n\u001b[0;32m--> 149\u001b[0m     \u001b[43mdelayfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     action(\u001b[38;5;241m*\u001b[39margument, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sched\n",
    "import time\n",
    "import yfinance as yf\n",
    "\n",
    "handler_for_errors = logging.FileHandler(\"errors.log\", mode='w')\n",
    "handler_for_info = logging.FileHandler(\"logging_de.log\", mode='w')\n",
    "handler_for_errors.setFormatter(logging.Formatter(fmt = \"%(asctime)s %(name)s %(levelname)s %(message)s\", \\\n",
    "                                                      datefmt = \"%Y-%m-%d %H:%M:%S\")) \n",
    "handler_for_info.setFormatter(logging.Formatter(fmt = \"%(asctime)s %(name)s %(levelname)s %(message)s\", \\\n",
    "                                                      datefmt = \"%Y-%m-%d %H:%M:%S\"))\n",
    "class ErrorFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return record.levelno >= logging.ERROR\n",
    "handler_for_errors.addFilter(ErrorFilter())\n",
    "\n",
    "class InfoWarningFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return record.levelno <= logging.WARNING\n",
    "handler_for_info.addFilter(InfoWarningFilter())\n",
    "\n",
    "logger = logging.getLogger(\"logger\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(handler_for_errors)\n",
    "logger.addHandler(handler_for_info)\n",
    "\n",
    "tick_seconds = 2\n",
    "def current_stock_df_name(stock_name):\n",
    "    return \"current_\" + stock_name + \".csv\"\n",
    "\n",
    "def history_stock_df_name(stock_name):\n",
    "    return \"history_\" + stock_name + \".csv\"\n",
    "\n",
    "def initialize_file_if_not_exists(filename, file_content):\n",
    "    if not (os.path.isfile(filename)):\n",
    "        initialized_file = open(filename, \"w\")\n",
    "        initialized_file.write(file_content)\n",
    "        initialized_file.close()\n",
    "        \n",
    "last_request = {}\n",
    "last_update = {}\n",
    "    \n",
    "requests_filename = \"current_requests.csv\"\n",
    "stats_filename = \"requests_stats.csv\"\n",
    "stats_header = \"timestamp,stock,requests\\n\"\n",
    "stock_df_header = \"Datetime,Open,High,Low,Close,Adj Close,Volume\\n\"\n",
    "iteration_id = 0\n",
    "\n",
    "def update_stocks_collect_stat(scheduler): \n",
    "    \n",
    "    global iteration_id\n",
    "    global tick_seconds, requests_filename, stats_filename, stats_header, stock_df_header\n",
    "    global last_request, last_update\n",
    "    \n",
    "    import_interval = \"5m\"\n",
    "    period_of_import = \"60m\"\n",
    "    request_threshold = datetime.timedelta(seconds = 30)\n",
    "    \n",
    "    logger.info(f\"Iteration {iteration_id} started\")\n",
    "    iteration_timestamp = datetime.datetime.now()\n",
    "    \n",
    "    \n",
    "    logger.debug(f\"Checking for new requests\")\n",
    "    if (os.path.isfile(requests_filename)):\n",
    "        logger.debug(f\"New requests detected\")\n",
    "        requests = open(requests_filename, \"r\")\n",
    "        requests_heading = requests.readline()\n",
    "        initialize_file_if_not_exists(stats_filename, stats_header)\n",
    "        stats = open(stats_filename, \"a\")\n",
    "        for raw_row in requests:\n",
    "            row = raw_row.split(\",\")\n",
    "            stock_name = row[0]\n",
    "            if ((stock_name not in last_request) or \\\n",
    "                (datetime.datetime.now() - last_request[stock_name] > request_threshold)):\n",
    "                try:\n",
    "                    logger.debug(f\"Start updating {stock_name}\")\n",
    "                    if (os.path.isfile(current_stock_df_name(stock_name))):\n",
    "                        logger.debug(f\"Rewrite {stock_name} current information into history\")\n",
    "                        initialize_file_if_not_exists(history_stock_df_name(stock_name), stock_df_header)\n",
    "                        history_df = open(history_stock_df_name(stock_name), \"a\")\n",
    "                    \n",
    "                        cur_df = open(current_stock_df_name(stock_name), \"r\")\n",
    "                        cur_df.readline()\n",
    "                        for cur_df_row in cur_df:\n",
    "                            history_df.write(cur_df_row)\n",
    "                        cur_df.close()\n",
    "                        history_df.close()\n",
    "                        logger.debug(f\"{stock_name} current information is saved into history\")\n",
    "                    last_request[stock_name] = datetime.datetime.now()\n",
    "                    cur_df = yf.download(tickers = stock_name, period = period_of_import, interval = import_interval)\n",
    "                    cur_df.to_csv(current_stock_df_name(stock_name))\n",
    "                    logger.debug(f\"{stock_name} data updated\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error {e} occured while getting data\")\n",
    "            stats.write(str(iteration_timestamp) + \",\")\n",
    "            stats.write(raw_row)\n",
    "        stats.write(\"\\n\")\n",
    "        requests.close()\n",
    "        stats.close()\n",
    "        os.remove(requests_filename)\n",
    "        logger.debug(f\"Requests cleared\")\n",
    "    else:\n",
    "        logger.debug(f\"No new requests\")\n",
    "    logger.info(f\"Iteration {iteration_id} finished\")\n",
    "    scheduler.enter(tick_seconds, 1, update_stocks_collect_stat, (scheduler,))\n",
    "    iteration_id += 1\n",
    "\n",
    "my_scheduler = sched.scheduler(time.time, time.sleep)\n",
    "my_scheduler.enter(tick_seconds, 1, update_stocks_collect_stat, (my_scheduler,))\n",
    "my_scheduler.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d77b60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "cur_df = yf.download(tickers = \"TSLA\", period = \"5d\", interval = \"60m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7ec42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "stock_data = yf.download(tickers = \"AAPL\", period =\"15m\", interval = \"1m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0adbb0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191.74850463867188\n"
     ]
    }
   ],
   "source": [
    "stock_ticker = yf.Ticker(\"AAPL\") \n",
    "\n",
    "stock_df = stock_data.history(period = '1d')\n",
    "\n",
    "if not stock_df.empty: \n",
    "    stock_price = stock_df['Close'].iloc[-1] \n",
    "\n",
    "print(stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54686cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
